# LangChaninProjects

# Local-First AI Chatbot: Groq + Ollama2 + Streamlit + LangChain

Interactive chatbot supporting **dual LLM backends**â€”fast cloud inference (Groq) and fully local/private (Ollama Llama2). Perfect for ML demos, interviews, and portfolio showcase.

## âœ¨ Features
- **Dual-mode**: Toggle between Groq (cloud, ultra-fast) and Ollama Llama2 (local, offline)
- **LangChain**: Clean prompt chaining + parsing pipeline
- **Streamlit**: Production-ready UI deployed to cloud
- **Hybrid workflow**: Local dev â†’ Cloud sharing

## ğŸ› ï¸ Quick Start (Local)

### Prerequisites
```bash
pip install -r requirements.txt
```

### Local Ollama Setup
```bash
# Install Ollama (Windows: ollama.com/download)
ollama pull llama2  # ~4GB, runs on CPU/GPU
```

### Run
```bash
# Local with Ollama
streamlit run app.py --server.headless true
```

**Live URL**: `http://localhost:8501`

## â˜ï¸ Cloud Deployment (Groq)
1. Push to GitHub (`.env` excluded via `.gitignore`)
2. Deploy: [share.streamlit.io](https://share.streamlit.io)
3. Auto-uses Groq (cloud) for public demos

## ğŸ“ Project Structure
```
.
â”œâ”€â”€ app.py              # Main Streamlit + LangChain app
â”œâ”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ .env.example        # API keys template
â”œâ”€â”€ README.md           # This file
â””â”€â”€ .gitignore          # Excludes secrets
```

## ğŸ”§ Configuration

### `.env` (Local Only)
```env
GROQ_API_KEY=your_groq_key_here
LANGCHAIN_API_KEY=your_langsmith_key_here  # Optional tracing
```

### Model Toggle (groq_api.py)
```python
# Switch easily:
llm = ChatGroq(model="llama3-8b-8192")     # Cloud (deploy-ready)
# llm = ChatOllama(model="llama2")         # Local (offline)
```

## ğŸš€ Performance
| Backend | Speed | Cost | Privacy | Use Case |
|---------|-------|------|---------|----------|
| **Groq** | âš¡ 200+ tokens/sec | Free tier | Cloud | Demos, LinkedIn |
| **Ollama2** | ğŸŒ 10-30 tokens/sec | Free | 100% Local | Dev, Offline |

## ğŸ“± Screenshots
*(Add your app screenshots here)*

## ğŸ”— Live Demo
**[Try Live â†’](https://your-app.streamlit.app)**  


## ğŸ’¼ For Interviews/Portfolio
- **Local**: Shows Ollama + LangChain skills (offline capable)
- **Cloud**: Production deployment + GitHub workflow
- **Dual**: Backend flexibility awareness

## ğŸ› ï¸ Tech Stack
```
Frontend: Streamlit
Backend: LangChain + (Groq/Ollama)
Models: Llama3-8B (Groq), Llama2-7B (Ollama)
Environment: Python 3.10+
```

***

**Built by Jonnagiri Vamsi Krishna** | #AI #MachineLearning #Streamlit #Ollama #LangChain

***

